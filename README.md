# ğŸ” ValidaciÃ³n de Factibilidad: Dataset SintÃ©tico + ML + OptimizaciÃ³n VRP

## ğŸ“‹ **Objetivo de esta Fase**

Desarrollar y validar de forma autÃ³noma los componentes fundamentales del sistema de ruteo de Ãºltima milla para evaluar:
- **Realismo del dataset sintÃ©tico** (evitar mÃ©tricas ML artificialmente perfectas)
- **Factibilidad de la optimizaciÃ³n** (convergencia y interpretabilidad)
- **IntegraciÃ³n ML â†’ OptimizaciÃ³n** (flujo de datos coherente)
- **Insights pedagÃ³gicos** (resultados Ãºtiles para estudiantes)

**Criterio de Ã©xito:** Generar evidencia suficiente para redefinir/ajustar el proyecto principal basÃ¡ndose en resultados empÃ­ricos.

---

## ğŸ—ï¸ **Arquitectura del Sistema de ValidaciÃ³n**

```
Dataset SintÃ©tico (50 clientes, 5 dÃ­as) 
         â†“
RandomForest Predictor (tiempos de viaje + disponibilidad)
         â†“  
MINLP Optimizer (VRP con ventanas de tiempo)
         â†“
Dashboard de AnÃ¡lisis (mÃ©tricas + visualizaciones)
```

---

## ğŸ“ **Estructura del Proyecto**

```
vrp_validation/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â””â”€â”€ validation_config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ synthetic/           # Dataset generado
â”‚   â””â”€â”€ results/             # Resultados de validaciÃ³n
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_generator.py    # GeneraciÃ³n dataset real-scale
â”‚   â”œâ”€â”€ ml_pipeline.py       # RandomForest + validaciÃ³n
â”‚   â”œâ”€â”€ optimization_model.py # FormulaciÃ³n MINLP
â”‚   â””â”€â”€ analysis_dashboard.py # Dashboard anÃ¡lisis
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ validation_results.ipynb
â””â”€â”€ tests/
    â””â”€â”€ test_integration.py
```

---

## ğŸ¯ **Componente 1: Generador de Dataset Real-Scale**

### **EspecificaciÃ³n del Dataset:**
- **Escala:** 50 clientes, 3 vehÃ­culos, 5 dÃ­as operativos
- **Ãrea geogrÃ¡fica:** Grid urbano 15x15 km (ciudad media)
- **Complejidad:** Patrones temporales realistas + correlaciones imperfectas
- **Incertidumbre:** Variabilidad en tiempos de viaje (Â±20%) y disponibilidad cliente (70-95%)

### **Estructura de Datos:**

#### **customers.csv**
```python
{
    'customer_id': int,
    'lat': float, 'lon': float,        # Coordenadas realistas
    'demand_kg': float,                # 5-50 kg por entrega
    'service_time_min': float,         # 5-20 minutos
    'time_window_start': int,          # 8-18 horas
    'time_window_end': int,            # window_start + 2-6 horas  
    'availability_base_prob': float,   # 0.7-0.95
    'customer_type': str,              # 'residential', 'business', 'priority'
    'access_difficulty': float         # Factor que afecta service_time
}
```

#### **historical_deliveries.csv (para entrenamiento ML)**
```python
{
    'delivery_id': int,
    'customer_id': int,
    'date': datetime,
    'planned_arrival': datetime,
    'actual_arrival': datetime,
    'travel_time_min': float,          # Target para ML
    'customer_available': bool,        # Target para ML
    'weather': str,                    # 'sunny', 'rain', 'cloudy'
    'traffic_level': float,            # 1.0-2.5 multiplicador
    'day_of_week': int,
    'hour_of_day': int,
    'distance_km': float,
    'previous_stop_delay': float       # Retraso acumulado
}
```

#### **vehicles.csv**
```python
{
    'vehicle_id': int,
    'capacity_kg': float,              # 200-500 kg
    'cost_per_km': float,              # 0.8-1.2 EUR/km
    'max_working_hours': int,          # 8-10 horas
    'depot_lat': float, 'depot_lon': float
}
```

### **GeneraciÃ³n de Realismo:**
- **Distribuciones asimÃ©tricas** (no perfectamente gaussianas)
- **Correlaciones con ruido:** distancia-tiempo con factor aleatorio Â±15%
- **Patrones estacionales:** rush hours, dÃ­as de semana vs weekend
- **Outliers controlados:** 5% de casos "difÃ­ciles" (cliente no disponible, trÃ¡fico extremo)

---

## ğŸ¤– **Componente 2: Pipeline RandomForest**

### **Objetivo:** Predecir tiempos de viaje y disponibilidad del cliente

### **Features Engineering:**
```python
# Para predicciÃ³n de tiempos de viaje
travel_features = [
    'distance_km',
    'hour_of_day', 'day_of_week',
    'weather_encoded',
    'traffic_level',
    'road_type_factor',
    'previous_stop_delay',
    'vehicle_type_encoded'
]

# Para predicciÃ³n de disponibilidad cliente  
availability_features = [
    'customer_availability_base_prob',
    'hour_of_day', 'day_of_week',
    'customer_type_encoded', 
    'weather_encoded',
    'previous_failed_attempts',
    'time_since_last_delivery'
]
```

### **ImplementaciÃ³n:**
```python
class VRPPredictor:
    def __init__(self):
        self.travel_model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        self.availability_model = RandomForestClassifier(
            n_estimators=100,
            max_depth=8, 
            random_state=42,
            class_weight='balanced'
        )
    
    def train_and_validate(self, data):
        """
        Entrenamiento con validaciÃ³n temporal estricta:
        - Training: dÃ­as 1-20
        - Validation: dÃ­as 21-25  
        - Test: dÃ­as 26-30
        """
        pass
    
    def predict_with_uncertainty(self, X):
        """
        Retornar predicciÃ³n + intervalo de confianza
        usando std de Ã¡rboles en RandomForest
        """
        pass
```

### **Validaciones EspecÃ­ficas:**
- **Cross-validation temporal:** No aleatorio, respeta orden cronolÃ³gico
- **CalibraciÃ³n probabilÃ­stica:** Para predicciones de disponibilidad
- **Feature importance:** AnÃ¡lisis de quÃ© variables son mÃ¡s predictivas
- **Residual analysis:** Detectar bias en predicciones

---

## âš™ï¸ **Componente 3: FormulaciÃ³n MINLP del VRP**

### **FormulaciÃ³n MatemÃ¡tica:**

#### **Conjuntos:**
- `C = {1,2,...,50}`: Clientes
- `V = {0,1,2,...,50}`: Nodos (0=depot)
- `K = {1,2,3}`: VehÃ­culos  
- `T = {480,490,...,1080}`: Slots de tiempo (8:00-18:00 en minutos)

#### **Variables de DecisiÃ³n:**
```python
# Variables binarias
x[i,j,k] = 1 si vehÃ­culo k va de i a j
s[i,k] = 1 si vehÃ­culo k sirve cliente i
z[i,t] = 1 si cliente i es visitado en slot t

# Variables continuas  
arrival_time[i,k] = momento de llegada del vehÃ­culo k al cliente i
load[i,k] = carga del vehÃ­culo k al salir del nodo i
```

#### **ParÃ¡metros (Predichos por ML):**
```python
travel_time[i,j] = tiempo predicho por RandomForest
availability_prob[i,t] = probabilidad cliente disponible en slot t
service_time[i] = tiempo de servicio en cliente i
demand[i] = demanda del cliente i
```

#### **FunciÃ³n Objetivo:**
```
minimize:
    Î£(i,j,k) cost_per_km[k] * distance[i,j] * x[i,j,k] +           # Coste transporte
    Î£(i,t) penalty_unavailable * (1-availability_prob[i,t]) * z[i,t] # PenalizaciÃ³n riesgo
```

#### **Restricciones Principales:**
```python
# Cada cliente servido exactamente una vez
âˆ€iâˆˆC: Î£(k) s[i,k] = 1

# ConservaciÃ³n de flujo
âˆ€kâˆˆK, jâˆˆV: Î£(i) x[i,j,k] = Î£(i) x[j,i,k]

# Ventanas de tiempo
âˆ€iâˆˆC: time_window_start[i] â‰¤ arrival_time[i,k] â‰¤ time_window_end[i]

# Precedencia temporal con tiempos ML
âˆ€i,jâˆˆV, kâˆˆK: arrival_time[i,k] + service_time[i] + travel_time[i,j] 
              â‰¤ arrival_time[j,k] + M*(1-x[i,j,k])

# Capacidad vehÃ­culos
âˆ€kâˆˆK: Î£(i) demand[i] * s[i,k] â‰¤ capacity[k]

# Jornada laboral
âˆ€kâˆˆK: arrival_time[depot,k] â‰¤ max_working_hours[k] * 60
```

### **ImplementaciÃ³n:**
```python
import pulp
from ortools.linear_solver import pywraplp

class VRPOptimizer:
    def __init__(self, solver='CBC'):
        self.solver_name = solver
        self.model = None
        self.solution = None
        
    def formulate_minlp(self, customers, vehicles, ml_predictions):
        """
        Crear modelo MINLP completo con predicciones ML
        """
        pass
    
    def solve_with_analysis(self, time_limit=600):
        """
        Resolver + anÃ¡lisis de sensibilidad automÃ¡tico
        """
        pass
    
    def extract_solution_insights(self):
        """
        Extraer insights interpretables:
        - QuÃ© restricciones estÃ¡n activas
        - UtilizaciÃ³n de vehÃ­culos  
        - Patterns en las rutas
        - Sensibilidad a parÃ¡metros clave
        """
        pass
```

---

## ğŸ“Š **Componente 4: Dashboard de AnÃ¡lisis**

### **MÃ©tricas de ValidaciÃ³n a Reportar:**

#### **ML Performance:**
```python
ml_metrics = {
    # PredicciÃ³n tiempos de viaje
    'travel_time_mae': float,           # Target: 10-25% del promedio
    'travel_time_r2': float,            # Target: 0.6-0.8 
    'travel_time_mape': float,
    
    # PredicciÃ³n disponibilidad
    'availability_auc': float,          # Target: 0.7-0.85
    'availability_precision': float,
    'availability_recall': float,
    'calibration_score': float,         # Reliability diagram
    
    # Estabilidad temporal
    'temporal_stability': float,        # Performance dÃ­as 21-25 vs 26-30
    'feature_importance_stability': dict
}
```

#### **Optimization Performance:**  
```python
optimization_metrics = {
    # Convergencia
    'solve_time_seconds': float,        # Target: <300s
    'optimality_gap': float,            # Target: <5%
    'solver_status': str,               # 'Optimal', 'Feasible', etc.
    
    # Calidad de soluciÃ³n
    'total_distance_km': float,
    'total_time_hours': float, 
    'vehicle_utilization': dict,        # Por vehÃ­culo
    'time_window_violations': int,
    
    # Interpretabilidad
    'active_constraints': dict,         # CuÃ¡les estÃ¡n en el lÃ­mite
    'shadow_prices': dict,              # Valor marginal restricciones
    'solution_robustness': float        # Sensibilidad a cambios ML
}
```

#### **Integration Health:**
```python
integration_metrics = {
    # Flujo ML â†’ Opt
    'prediction_to_optimization_time': float,
    'parameter_consistency_checks': dict,
    'extreme_predictions_handled': bool,
    
    # Business insights
    'cost_vs_service_tradeoff': dict,
    'bottleneck_identification': list,
    'scalability_indicators': dict
}
```

### **Visualizaciones AutomÃ¡ticas:**
1. **Mapa de rutas** con clientes coloreados por disponibilidad predicha
2. **DistribuciÃ³n de mÃ©tricas ML** vs benchmarks tÃ­picos  
3. **AnÃ¡lisis de sensibilidad** de la optimizaciÃ³n
4. **Timeline de convergencia** del solver
5. **Feature importance** de modelos ML
6. **Correlation matrix** entre parÃ¡metros y KPIs de negocio

### **ImplementaciÃ³n Dashboard:**
```python
import matplotlib.pyplot as plt
import seaborn as sns
import folium
import plotly.express as px

class ValidationDashboard:
    def __init__(self, ml_results, optimization_results, raw_data):
        self.ml_results = ml_results
        self.opt_results = optimization_results  
        self.data = raw_data
        
    def generate_full_report(self):
        """
        Generar reporte completo con:
        1. Executive summary de viabilidad
        2. AnÃ¡lisis detallado por componente
        3. Recomendaciones para proyecto principal
        4. Red flags identificados
        """
        pass
    
    def plot_ml_performance(self):
        """Visualizar mÃ©tricas ML vs umbrales aceptables"""
        pass
        
    def plot_optimization_analysis(self):
        """AnÃ¡lisis de convergencia y interpretabilidad"""
        pass
        
    def plot_route_visualization(self):
        """Mapa interactivo con rutas optimizadas"""
        pass
```

---

## ğŸ¯ **Criterios de EvaluaciÃ³n de la ValidaciÃ³n**

### **ğŸŸ¢ SeÃ±ales Positivas (Proceder con proyecto principal):**
- ML RÂ² entre 0.6-0.8 (no artificialmente alto)
- OptimizaciÃ³n converge en <5 minutos con gap <5%
- Soluciones muestran trade-offs interpretables
- Predicciones ML impactan significativamente en rutas Ã³ptimas
- Insights pedagÃ³gicos claros emergen del anÃ¡lisis

### **ğŸŸ¡ SeÃ±ales de Alerta (Ajustar enfoque):**
- ML RÂ² >0.9 (datos demasiado "perfectos")
- OptimizaciÃ³n muy sensible a pequeÃ±os cambios en predicciones
- Soluciones difÃ­ciles de interpretar o contradictorias
- Tiempo de solve >10 minutos consistentemente

### **ğŸ”´ Red Flags (RediseÃ±ar completamente):**
- ML colapsa en validaciÃ³n temporal
- Problemas de optimizaciÃ³n infactibles
- Resultados tÃ©cnicamente correctos pero pedagÃ³gicamente vacÃ­os
- IntegraciÃ³n MLâ†’Opt introduce errores sistemÃ¡ticos

---

## ğŸ“‹ **ConfiguraciÃ³n para Claude Code**

### **requirements.txt**
```
pandas>=1.5.0
numpy>=1.21.0
scikit-learn>=1.1.0
matplotlib>=3.5.0
seaborn>=0.11.0
plotly>=5.10.0
folium>=0.12.0

# Optimization
pulp>=2.6.0
ortools>=9.4.0

# Development
pytest>=7.0.0
jupyter>=1.0.0
pyyaml>=6.0.0
```

### **Orden de ImplementaciÃ³n para Claude Code:**
1. **Crear estructura de carpetas** segÃºn especificaciÃ³n
2. **Implementar data_generator.py** con dataset de 50 clientes realista
3. **Desarrollar ml_pipeline.py** con RandomForest y validaciÃ³n temporal
4. **Formular optimization_model.py** con MINLP completo
5. **Construir analysis_dashboard.py** con mÃ©tricas y visualizaciones
6. **Integrar todos los componentes** en pipeline automatizado
7. **Generar notebook final** con anÃ¡lisis completo de resultados

### **Test de IntegraciÃ³n:**
```python
def test_full_pipeline():
    """Test end-to-end del sistema de validaciÃ³n"""
    # Generar datos
    dataset = generate_synthetic_data(n_customers=50, n_days=5)
    
    # Entrenar ML
    ml_model = train_ml_pipeline(dataset)
    
    # Resolver optimizaciÃ³n  
    solution = solve_vrp_minlp(dataset, ml_model.predictions)
    
    # Validar resultados
    assert solution.status == 'Optimal'
    assert ml_model.r2_score < 0.9  # No artificialmente perfecto
    assert solution.solve_time < 600  # Converge en tiempo razonable
```

---

## ğŸ¯ **Output Esperado de esta ValidaciÃ³n**

Al completar esta fase, deberÃ¡s tener:

1. **Reporte ejecutivo** con recomendaciÃ³n clara: Â¿Proceder, ajustar, o rediseÃ±ar?
2. **Dataset sintÃ©tico validado** que produce ML/optimizaciÃ³n realistas
3. **Baseline de performance** para componentes ML y optimizaciÃ³n  
4. **IdentificaciÃ³n de bottlenecks** y aspectos mÃ¡s pedagÃ³gicamente valiosos
5. **Roadmap ajustado** para el proyecto principal basado en evidencia empÃ­rica

**Este anÃ¡lisis serÃ¡ la base para decidir si el CLAUDE.md del proyecto principal necesita modificaciones en complejidad, enfoque, o estructura pedagÃ³gica.**
